{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NpMi6bG9z1t"
      },
      "source": [
        "Faça o upload de um arquivo .zip com os seus dados e use o comando abaixo após a finalização do upload para a extração do conteúdo do arquivo no colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>steer</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>breaking</th>\n",
              "      <th>speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>22277.000000</td>\n",
              "      <td>22277.000000</td>\n",
              "      <td>22277.0</td>\n",
              "      <td>22277.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.034986</td>\n",
              "      <td>0.997656</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.142515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.073005</td>\n",
              "      <td>0.045735</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.032279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.314554</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.061033</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.028169</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.190250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-0.009390</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.190300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.352113</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.637620</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              steer  acceleration  breaking         speed\n",
              "count  22277.000000  22277.000000   22277.0  22277.000000\n",
              "mean      -0.034986      0.997656       0.0     30.142515\n",
              "std        0.073005      0.045735       0.0      1.032279\n",
              "min       -0.314554      0.000000       0.0      0.000002\n",
              "25%       -0.061033      1.000000       0.0     30.190000\n",
              "50%       -0.028169      1.000000       0.0     30.190250\n",
              "75%       -0.009390      1.000000       0.0     30.190300\n",
              "max        0.352113      1.000000       0.0     30.637620"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('todososdados.csv')\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#preparação dos dados\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('todososdados.csv')\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(data['steer'], bins=50, color='blue', alpha=0.7)\n",
        "plt.title('Distribuição dos Ângulos de Direção')\n",
        "plt.xlabel('Ângulo de Direção (steer)')\n",
        "plt.ylabel('Frequência')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smgD-6OS-KuL"
      },
      "source": [
        "Implemente as funções a seguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "__8dnSXJ_YtC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
            "    self._run_once()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
            "    handle._run()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\asyncio\\events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\moura\\AppData\\Local\\Temp\\ipykernel_5540\\1383444278.py\", line 6, in <module>\n",
            "    from torchvision.io import read_image\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\__init__.py\", line 6, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\models\\__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\models\\convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\ops\\__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\ops\\poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torchvision\\ops\\roi_align.py\", line 4, in <module>\n",
            "    import torch._dynamo\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 64, in <module>\n",
            "    torch.manual_seed = disable(torch.manual_seed)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\decorators.py\", line 50, in disable\n",
            "    return DisableContext()(fn)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 410, in __call__\n",
            "    (filename is None or trace_rules.check(fn))\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3378, in check\n",
            "    return check_verbose(obj, is_inlined_call).skipped\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3361, in check_verbose\n",
            "    rule = torch._dynamo.trace_rules.lookup_inner(\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3442, in lookup_inner\n",
            "    rule = get_torch_obj_rule_map().get(obj, None)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2782, in get_torch_obj_rule_map\n",
            "    obj = load_object(k)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2811, in load_object\n",
            "    val = _load_obj_from_str(x[0])\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2795, in _load_obj_from_str\n",
            "    return getattr(importlib.import_module(module), obj_name)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py\", line 417, in <module>\n",
            "    values=torch.randn(3, 3, device=\"meta\"),\n",
            "c:\\Users\\moura\\anaconda3\\envs\\visao\\Lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py:417: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
            "  values=torch.randn(3, 3, device=\"meta\"),\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0asP2qsKXuBN"
      },
      "outputs": [],
      "source": [
        "\n",
        "def add_random_shadow(image):\n",
        "    # Adiciona sombra aleatória como uma fatia vertical da imagem\n",
        "    h, w = image.shape[1], image.shape[2]\n",
        "    x1, x2 = np.random.choice(w, 2, replace=False)\n",
        "    k = h / (x2 - x1)\n",
        "    b = - k * x1\n",
        "    shadow_intensity = 0.5\n",
        "    for i in range(h):\n",
        "        c = int((i - b) / k)\n",
        "        if c > 0 and c < w:\n",
        "            image[:, i, :c] *= shadow_intensity\n",
        "    return image\n",
        "\n",
        "class CarSimDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, augment=True):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.augment = augment\n",
        "        self.cameras = ['left', 'center', 'right']\n",
        "        self.cameras_steering_correction = [.25, 0., -.25]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        camera_idx = np.random.randint(len(self.cameras)) if self.augment else 1\n",
        "        camera = self.cameras[camera_idx]\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx][camera].strip())\n",
        "        image = read_image(img_path).float() / 255.0  # Ler a imagem e normalizar os pixels\n",
        "        angle = self.img_labels.iloc[idx]['steer'] + self.cameras_steering_correction[camera_idx]\n",
        "\n",
        "        if self.augment:\n",
        "            # Adiciona sombra aleatória\n",
        "            image = add_random_shadow(image)\n",
        "            # Deslocamento vertical aleatório\n",
        "            v_delta = random.uniform(-0.05, 0.05)\n",
        "            top_offset = 0.375 + v_delta\n",
        "            bottom_offset = 0.125 + v_delta\n",
        "            top = int(top_offset * image.shape[1])\n",
        "            bottom = int(bottom_offset * image.shape[1])\n",
        "            image = image[:, top:-bottom, :]\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, angle\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Crie as variáveis a seguir a partir da classe implementada acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transformações específicas do PyTorch\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # Redimensiona a imagem\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalização\n",
        "])\n",
        "\n",
        "# Configuração do Dataset de Treinamento\n",
        "train_dataset = CarSimDataset(\n",
        "    annotations_file='C:\\\\Users\\\\moura\\\\Searches\\\\behavior-cloning\\\\todososdados.csv',\n",
        "    img_dir='DataAndLoader\\\\IMG',\n",
        "    transform=transform,\n",
        "    augment=True  # Ativa aumento de dados para treinamento\n",
        ")\n",
        "\n",
        "# Configuração do Dataset de Teste\n",
        "test_dataset = CarSimDataset(\n",
        "    annotations_file='C:\\\\Users\\\\moura\\\\Searches\\\\behavior-cloning\\\\todososdados.csv',\n",
        "    img_dir='DataAndLoader\\\\IMG',\n",
        "    transform=transform,\n",
        "    augment=False  # Desativa aumento de dados para teste\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of images: torch.Size([64, 3, 28, 28]), Shape of angles: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# DataLoader para o Treinamento\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# DataLoader para o Teste\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Exemplo de como iterar sobre o DataLoader de Teste\n",
        "for images, angles in test_dataloader:\n",
        "    print(f\"Shape of images: {images.shape}, Shape of angles: {angles.shape}\")\n",
        "    break  # Mostra apenas o primeiro lote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of images in the train dataset: 22277\n"
          ]
        }
      ],
      "source": [
        "# Verificar o número total de imagens no dataset\n",
        "num_images = len(train_dataset)\n",
        "print(f\"Total number of images in the train dataset: {num_images}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "\n",
        "def add_random_shadow(image):\n",
        "    h, w = image.shape[1], image.shape[2]\n",
        "    x1, x2 = np.random.choice(w, 2, replace=False)\n",
        "    k = h / (x2 - x1)\n",
        "    b = - k * x1\n",
        "    shadow_intensity = 0.5\n",
        "    for i in range(h):\n",
        "        c = int((i - b) / k)\n",
        "        if c > 0 and c < w:\n",
        "            image[:, i, :c] *= shadow_intensity\n",
        "    return image\n",
        "\n",
        "def add_random_brightness(image):\n",
        "    brightness_factor = np.random.uniform(0.5, 1.5)\n",
        "    image = image * brightness_factor\n",
        "    return image.clamp(0, 1) \n",
        "\n",
        "def random_rotate(image, angle):\n",
        "    angle = np.random.uniform(-angle, angle)\n",
        "    return transforms.functional.rotate(image, angle)\n",
        "\n",
        "class CarSimDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, augment=True):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.augment = augment\n",
        "        self.cameras = ['left', 'center', 'right']\n",
        "        self.cameras_steering_correction = [.25, 0., -.25]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.augment:\n",
        "            probs = np.abs(self.img_labels['steer']) #+ 0.01  # Evitar divisão por zero\n",
        "            probs /= probs.sum()  # Normalizar para formar uma distribuição de probabilidade\n",
        "            idx = np.random.choice(self.img_labels.index, p=probs)\n",
        "        \n",
        "        camera_idx = np.random.randint(len(self.cameras))\n",
        "        camera = self.cameras[camera_idx]\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx][camera].strip())\n",
        "        image = read_image(img_path).float() / 255.0\n",
        "\n",
        "        angle = self.img_labels.iloc[idx]['steer'] + self.cameras_steering_correction[camera_idx]\n",
        "\n",
        "        if self.augment:\n",
        "            image = add_random_shadow(image)\n",
        "            image = add_random_brightness(image)\n",
        "            image = random_rotate(image, 5)  # Rotação de até 5 graus\n",
        "\n",
        "            # Outras transformações aqui, se necessário\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, angle\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "# Transformações específicas do PyTorch\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # Ajustado para uma resolução maior\n",
        "    \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Configuração do Dataset de Treinamento\n",
        "train_dataset = CarSimDataset(\n",
        "    annotations_file='C:\\\\Users\\\\moura\\\\Searches\\\\behavior-cloning\\\\todososdados.csv',\n",
        "    img_dir='DataAndLoader\\\\IMG',\n",
        "    transform=transform,\n",
        "    augment=True\n",
        ")\n",
        "\n",
        "# Configuração do Dataset de Teste\n",
        "test_dataset = CarSimDataset(\n",
        "    annotations_file='C:\\\\Users\\\\moura\\\\Searches\\\\behavior-cloning\\\\todososdados.csv',\n",
        "    img_dir='DataAndLoader\\\\IMG',\n",
        "    transform=transform,\n",
        "    augment=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of images: torch.Size([64, 3, 28, 28]), Shape of angles: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# DataLoader para o Treinamento\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# DataLoader para o Teste\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Exemplo de como iterar sobre o DataLoader de Teste\n",
        "for images, angles in test_dataloader:\n",
        "    print(f\"Shape of images: {images.shape}, Shape of angles: {angles.shape}\")\n",
        "    break  # Mostra apenas o primeiro lote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of images in the train dataset: 22277\n"
          ]
        }
      ],
      "source": [
        "# Verificar o número total de imagens no dataset\n",
        "num_images = len(train_dataset)\n",
        "print(f\"Total number of images in the train dataset: {num_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXDLTbuqESux"
      },
      "source": [
        "O código abaixo será utilizado para treinar o modelo com o seu dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "5VJYlF1KSi44",
        "outputId": "d4f4b5c6-81ff-4871-86ae-1ac30dd54937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.float32\n"
          ]
        }
      ],
      "source": [
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROBTIl6pAESA",
        "outputId": "6e9f988b-ea0c-47ad-91de-0bef2b30448a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=2352, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28*3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits.squeeze()\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "PJxdeuCBBRc-"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "0Cw8XfLNBY97"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "b-T_bjFhBnOX"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            # correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    # correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "8x4aJZpNBqAt",
        "outputId": "3387f2ac-9b26-4b92-abf9-5738617078b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.084525  [   64/22277]\n",
            "loss: 0.036148  [ 6464/22277]\n",
            "loss: 0.062836  [12864/22277]\n",
            "loss: 0.056677  [19264/22277]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.042572 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.049517  [   64/22277]\n",
            "loss: 0.057229  [ 6464/22277]\n",
            "loss: 0.046532  [12864/22277]\n",
            "loss: 0.032012  [19264/22277]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.037673 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.040782  [   64/22277]\n",
            "loss: 0.033145  [ 6464/22277]\n",
            "loss: 0.040849  [12864/22277]\n",
            "loss: 0.031492  [19264/22277]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.034234 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.025317  [   64/22277]\n",
            "loss: 0.031435  [ 6464/22277]\n",
            "loss: 0.025879  [12864/22277]\n",
            "loss: 0.033688  [19264/22277]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.033961 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.027174  [   64/22277]\n",
            "loss: 0.019076  [ 6464/22277]\n",
            "loss: 0.028621  [12864/22277]\n",
            "loss: 0.023256  [19264/22277]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.032768 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.023091  [   64/22277]\n",
            "loss: 0.022805  [ 6464/22277]\n",
            "loss: 0.021015  [12864/22277]\n",
            "loss: 0.025297  [19264/22277]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.034160 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.018470  [   64/22277]\n",
            "loss: 0.016810  [ 6464/22277]\n",
            "loss: 0.022579  [12864/22277]\n",
            "loss: 0.023574  [19264/22277]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.034300 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.021787  [   64/22277]\n",
            "loss: 0.018570  [ 6464/22277]\n",
            "loss: 0.012699  [12864/22277]\n",
            "loss: 0.014445  [19264/22277]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.034109 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.018636  [   64/22277]\n",
            "loss: 0.011012  [ 6464/22277]\n",
            "loss: 0.014011  [12864/22277]\n",
            "loss: 0.016927  [19264/22277]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.038312 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.013367  [   64/22277]\n",
            "loss: 0.014903  [ 6464/22277]\n",
            "loss: 0.010698  [12864/22277]\n",
            "loss: 0.009192  [19264/22277]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.039502 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "5AaRBZ1gDxUP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model_preprocess3.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvtnIBFlD35c"
      },
      "source": [
        "Faça o download do seu modelo após o treinamento, caso queira testá-lo no simulador.\n",
        "\n",
        "O código a seguir demonstra como o modelo será usado para inferência no simulador. Caso seja necessário, altere a função *preprocess*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RVqjjnUOGc8F"
      },
      "outputs": [],
      "source": [
        "def preprocess(x):\n",
        "    # TODO: se necessário, alterar função\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1LLWerSXFjRR"
      },
      "outputs": [],
      "source": [
        "# model = NeuralNetwork().to(device)\n",
        "# model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZAI2oGcAGqsz"
      },
      "outputs": [],
      "source": [
        "# model.eval()\n",
        "# x = test_data[0][0]\n",
        "# with torch.no_grad():\n",
        "    # x = preprocess(x)\n",
        "    # x = x.to(device)\n",
        "    # pred = model(x)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
